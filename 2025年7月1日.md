# 2025年7月1日

## 老师的疑问：
CostaLomaChocolateMonster: 你的beta是shape parameter? 
    -- [是的，这里的beta指的是shape parameter也就是论文中的Gemma]

CostaLomaChocolateMonster: 然后你算一下entropy 
    -- [已解决]

## 今日安排：
1. 为钩子添加保存具体module名称的功能
    -- [完成，现在我们知道每一个module的东西存在哪一个bucket里面了。]
    -- [一个新的特性，我们现在的钩子将捕捉训练时的通信，至于开始训练前广播模型的部分，我们不再捕捉]

2. 将.pt文件转换为.h5格式方便读入 
    -- [完成，均已通过numpy.array_equal测试]

3. 计算目前拥有的数据的entropy 
    -- [完成，已保存文件并绘制柱状图]
    -- [请参见后文的统计报告]

4. 研究.h5格式同时保存多个.pt文件的可能性【利用offset尝试random acccess】
    -- [发现：.h5格式的压缩效果非常好。]
    -- [发现：他似乎可以作为一个巨大的文件，保存多个.pt文件]
    -- [进度：在研究如何设计数据结构；不影响主训练进程地转化和保存；offset]



## 琐事：
1. 修正代码，遵守那篇论文有关命名的convention
    -- [已完成，下一次使用的时候就没问题了]
2. 下载minimind的数据，等待日后使用，给HPC存储空间腾位置
    -- [2025年7月1日16:13:28：运行中]
    -- [2025年7月1日16:30:27：太慢了，要不直接废弃得了，后续有需要再跑一遍就是了……]

## ENTROPY 统计报告：
BASIC STATIC OF entropy:

count    284.000000
mean       0.744443
std        0.569232
min        0.000306
25%        0.217952
50%        0.672815
75%        1.233921
max        2.276608
Name: entropy, dtype: float64

结果喜人，在第一个Batch中产生的bucket，其grad的entropy基本都小于2.

而且绝大多数都是集中在0-1.5这个区间内。

甚至8%的数据entropy接近0.


数据的csv还有entropy的直方图随后附上。


## 疑问：
1. 目前能够按照各个module保存grad，但是为了不影响训练进程，我需要想一个别的办法保存这些数据，目前看下来是可以用subprocess等方法
    一个进程保存，另一个进程转化成一个巨大的文件

    但是呢我不确认哪一个格式更好，以及该怎么设计数据结构。以下是我的看法：
    1. h5文件，matlab原生支持，支持自定义数据结构存储像dict或者json一样嵌套保存
    2. 原.pt文件 -- matlab可以调用python，在经过转化即可开始计算entropy。
    3. 请问您的看法是？

2. minimind的数据搬运下来有点麻烦，请问是否直接废弃？