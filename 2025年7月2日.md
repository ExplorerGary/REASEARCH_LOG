# 2025年7月2日


## 老师的指示：
1. 删除minimind数据
    -- [已完成]
2. 尝试用zip再压缩数据 
    -- [要紧！]
3. 将Qwen的数据塞进若干个巨大H5当中，日后处理
    -- [在进行]
4. "你尽快算一下zip of original, zip of h5, entropy coding with EG code "
    -- [未完成]

    注： entropy coding with EG code 出自 backslash 论文:

    "2. We propose to use exp-Golomb (EG) codes for entropy coding of LLM parameters, whose distribution can be well-modeled by GG distributions. It has been   
    shown (Wen & Villasenor, 1999) that for GG sources, EG codes can achieve coding efficiency very close to the entropy limit, well over 90% in many cases. We 
    also find the optimal EG code with k=0 implementation can accommodate many applications."



## 今天的安排：
0. 设计H5数据结构 -- [完成]

    ## H5 package:

    由于硬盘容量限制（1.81TB/disc），因此我们一个pack规定为最高1.8T，不然就会写入失败。

    浅层树形数据结构：

    第一层： rank; epoch; step 中的 "B_{b}": 各个桶 键对值
    第二层： bucket中的 "name:grad_tensor 键对值" 这个是由hook保存下来的

    示例: 
        A H5 package:
            /
            ├── R_0_E_0_S_0/
            │   ├── B_0/
            │   │   ├── layer1.weight  → tensor
            │   │   ├── layer1.bias    → tensor
            │   ├── B_1/
            │   │   ├── layer2.weight  → tensor
            │   │   └── ...
            ├── R_0_E_0_S_1/
            │   └── B_2/
            │       └── layer3.weight
            ├── R_1_E_0_S_0/
            │   └── B_1/
            │       └── ...

    注： dtype我们省略了，因为这个我会在见到新模型的时候记录，然后后续直接调用就行了。

    注：后期的筛选维护因为使用了都是键对值，因此相对容易


    注：但相比于存储为连续数组，然后用offset保存，可能还是相对比较慢。
        -- [现在一个包里面放了1.8TB的数据，也就是60-65个step的数据，因此不会有性能瓶颈]
        -- [目前HPC可用容量为4.5TB，那就是155个step的容量。装不下的，不过我可以选择使用数据集的一部分子集训练]

        offset略微有点麻烦，因为我必须计算出每一个东西的长度，然后维护一个神奇的查询表，这个算起来头很大的…… 我可能需要一个星期才能处理完这个问题

        但我有思路，我现在知道每一个module的大小。

        我完全可以把它变成一个巨大的.bin文件，然后把所有的数据喂进去，然后通过一连串复杂的计算，找出 

        R_{r}_E_{e}_S_{s}_B_{b}_{name_of_module}到底藏在哪

1. 完善Qwen保存数据的逻辑 -- [完成]
    每次保存一个R_{r}_E_{e}_S_{s}_B_{b}.pt，内含一堆name:grad_tensor的键对值 

        尽可能连续地保存东西，省的到时候大批小文件在硬盘里堆得到处都是，减缓效率

    干的事：
    1. 添加了一个TrainerCallBack维护Epoch和Step，hook可以调用他们来获取相应的数据。
        -- [完成]

    2. 完成一个bucket的数据保存为一个.pt的逻辑
        -- [完成]

        -- [后续的提升，改进保存逻辑，尝试让保存尽可能少阻塞训练流程]
    

    

2. 完成尽可能不阻塞训练流程的转化系统
    
    -- [这是我第一个大程序，我还在设计整个逻辑，预计明天落地。]

    采用 “生产者——消费者”模式：训练器负责保存，有专门的脚本负责转化。
    每一个bucket都存在COMMUNICATION_LOG文件夹下：
        命名为：f"R_{rank}_E_{the_epoch}_S_{the_step}_B_{idx}.pt"
    

    这个工厂的任务就是全力开动16核CPU，开始将这些东西按照一个pack最大1.8TB，打包成pack_{000}.h5的巨大H5 pack
    
    尝试并行写入同一个.h5文件

    逻辑如下：
    
    监听……

        发现新pt
            阅读其名称：f"R_{rank}_E_{the_epoch}_S_{the_step}_B_{idx}.pt"
                在h5里寻找f"R_{rank}_E_{the_epoch}_S_{the_step}"
                -- 有：
                    判断容量是否充足：
                    -- 充足： 加入
                    -- 不足： 新建pack_{idx+1}.h5,接着打包

                -- 无： 
                    判断容量是否充足：
                    -- 充足： 新建后加入
                    -- 不足： 新建pack_{idx+1}.h5,新建后加入
            
            在查表中记录去向
            
    

    注： 转化完就del原.pt文件 -- 安全的，因为转h5通过了numpy.array_same测试

3. 计算压缩边界
    -- [未完成，已经有私立]


## 笔记：
1. 找到了LLM可用的 benchmark dataset:
    Sentiment	    IMDB
    Spam	        Enron-Spam
    Topic	        20 Newsgroups	
    Q-A             SQuAD
    Translation	    WMT-19